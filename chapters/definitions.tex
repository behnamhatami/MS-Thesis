
\فصل{مفاهیم اولیه}

در این فصل به تعریف و بیان مفاهیم پایه‌ا‌ی مورد استفاده در فصل‌های بعد می‌پردازیم. با توجه به مطالب مورد نیاز در فصل‌های آتی، مطالب این فصل به سه بخش، مسائل ان‌پی-سخت، الگوریتم‌های تقریبی و الگوریتم‌های جویبارداده تقسیم می‌شود.

\قسمت{مسائل ان‌پی-سخت}
یکی از اولین سوال‌های بنیادی مطرح در علم کامپیوتر، اثبات \مهم{عدم حل پذیری} بعضی از مسائل است. به عنوان نمونه، می‌توان از دهمین مسئله‌ی هیلبرت\پاورقی{Hilbert} در گنگره‌ی ریاضی یاد کرد. هیلبرت این مسئله را این‌گونه بیان کرد:‌ ''فرآیندی طراحی کنید که در تعداد متناهی گام بررسی کند که آیا یک چندجمله‌ای، ریشه‌ی صحیح\پاورقی{Integral root} دارد یا خیر ``. با مدل محاسباتی که به‌وسیله‌ی تورینگ\پاورقی{Touring} ارائه‌ شد، این مسئله معادل پیدا کردن الگوریتمی برای این مسئله است که اثبات می‌شود امکان‌پذیر نیست \مرجع{sipser2012introduction}. برخلاف مثال بالا، عمده‌ی مسائل علوم کامپیوتر از نوع بالا نیستند و برای طیف وسیعی از آن‌ها، الگوریتم‌های پایان‌پذیر وجود دارد. بیش‌تر تمرکز علوم کامپیوتر هم بر روی چنین مسائلی است.

اگر چه برای اکثر مسائل، الگوریتمی پایان‌پذیر وجود دارد، اما وجود چنین الگوریتمی لزومی بر حل شدن چنین مسائلی نیست. در عمل، علاوه بر وجود الگوریتم، میزان کارامدی\پاورقی{Efficiency} الگوریتم نیز مطرح می‌گردد. به طور مثال، اگر الگوریتم حل یک مسئله مرتبه‌ی بالا یا نمایی داشته باشد، الگوریتم ارائه شده برای آن مسئله برای ورودی‌های نسبتا بزرگ قابل اجرا نیست و نمی‌توان از آن‌ها برای حل مسئله استفاده کرد. برای تشخیص و تمیز کارآمدی الگوریتم‌های مختلف و همچنین میزان سختی مسائل در امکان ارائه‌ی الگوریتم‌های کارآمد یا غیرکارآمد، نظریه‌ی پیچیدگی\پاورقی{Complexity theory}، دسته‌بندی‌های مختلفی برای سختی مسائل و حل‌پذیری آن‌ها ارائه داده است تا بتوان به‌طور رسمی\پاورقی{Formal} در مورد این معیار‌ها صحبت کرد. برای دسته‌بندی مسائل در نظریه‌ی پیچیدگی، ابتدا آن‌ها را به صورت تصمیم‌پذیر بیان می‌کنند.

\مسئله{\مهم{(مسائل تصمیم‌گیری)}\پاورقی{Decision problems} به دسته‌ای از مسائل گفته می‌شود که پاسخ آن‌ها تنها بله یا خیر است.}

به عنوان مثال، اگر بخواهیم مسئله‌ی $1$-مرکز در فضای $\IR^d$ را به صورت تصمیم پذیر بیان کنیم، به مسئله‌ی زیر می‌رسیم:

\مسئله{\مهم{(نسخه‌ی تصمیم پذیر $1$-مرکز)} مجموعه‌ی نقاط در فضا $\IR^d$ و شعاع $r$ داده شده است، آیا دایره‌ای به شعاع $r$ وجود دارد که تمام نقاط را بپوشاند؟}

در نظریه‌ی پیچیدگی، می‌توان گفت عمده‌ترین دسته‌بندی موجود، دسته‌بندی مسائل تصمیم‌گیری به مسائل پی $(P)$ و  ان‌پی $(NP)$ است. رده‌ی مسائل $P$، شامل تمامی مسائل تصمیم‌گیری است که راه‌حل چندجمله‌ای برای آن‌ها وجود دارد. از طرفی رده‌ی مسائل $NP$، شامل تمامی مسائل تصمیم‌گیری است که در زمان چندجمله‌ای قابل صحت‌سنجی\پاورقی{Verifiable} اند. تعریف صحت‌سنجی در نظریه پیچیدگی، یعنی اگر جواب مسئله‌ی تصمیم‌گیری بله باشد، می‌توان اطلاعات اضافی با طول چندجمله‌ای ارائه داد، که در زمان چند‌جمله‌ای از روی آن، می‌توان جواب بله الگوریتم را تصدیق نمود. به طور مثال، برای مسئله‌ی $1$-مرکز، کافی است به عنوان تصدیق جواب بله، مرکز دایره‌ی پوشاننده، ارائه داده شود. در این صورت، می‌توان با مرتبه‌ی خطی بررسی نمود که تمام نقاط داخل این دایره قرار می‌گیرند یا نه. برای مطالعه‌ی بیش‌تر و تعاریف دقیق‌تر می‌توان به  مرجع \مرجع{sipser2012introduction} مراجعه نمود.

همان‌طور که می‌دانید درستی یا عدم درستی $P \subset NP$ از جمله معروف‌ترین مسائل حل نشده\پاورقی{Open problem} در نظریه پیچیدگی است. حدس بسیار قوی وجود دارد که $P \neq NP$ و بسیاری ار مسائل، با این فرض حل می‌شوند و در صورتی که زمانی، خلاف این فرض اثبات گردد، آن‌گاه قسمت عمده‌ای از علوم کامپیوتر زیر سوال می‌رود.

در نظریه‌ی پیچیدگی، برای دسته‌بندی مسائل، یکی از روش‌های دسته‌بندی کاهش چند‌جمله‌ای\پاورقی{Polynomial Reduction} مسائل به یک‌دیگر است. 

\تعریف{می‌گوییم مسئله‌ی $A$ در زمان چندجمله‌ای به مسئله‌ی $B$ کاهش می‌یابد، اگر وجود داشته باشد الگوریتم چندجمله‌ای $C$ که به ازای هر ورودی $\alpha$ برای مسئله‌ی $A$، یک ورودی $\beta$ در زمان چندجمله‌ای برای مسئله‌ی $B$ بسازد، به طوری که $A$، $\alpha$ را می‌پذیرد اگر و تنها اگر $B$، $\beta$ را بپذیرد. در این‌جا منظور از پذیرفتن جواب بله به ورودی است.}

از این به بعد برای سادگی به جای \مهم{کاهش چندجمله‌ای} از واژه‌ی \مهم{کاهش} استفاده می‌کنیم. در پی جست‌جوهایی که برای برابری دسته‌ی پی و ان‌پی صورت گرفت، مجموعه‌ای از مسائل که عمدتا داخل ان‌پی هستند استخراج گردید که اگر ثابت شود یکی از آن‌ها متعلق به پی است، آن‌گاه تمام مسائل دسته‌ی ان‌پی متعلق به پی خواهند بود و در نتیجه $P = NP$ خواهد بود. به این مجموعه مسائل ان‌پی-سخت می‌گویند. در واقع مسائل این دسته، مسائلی هستند که تمام مسائل داخل دسته‌ی ان‌پی، به آن‌ها کاهش می‌یابند.

کوک و لوین در قضیه‌ای به نام \مهم{قضیه‌ی کوک-لوین} ثابت کردند مسئله‌ی صدق‌پذیری\پاورقی{Satisfiability problem} یک مسئله‌ی ان‌پی-سخت است \مرجع{sipser2012introduction}. با پایه قرار دادن این اثبات و استفاده از تکنیک کاهش، اثبات ان‌پی-سخت بودن سایر مسائل، بسیار ساده‌تر گردید. در ادامه مسئله‌ی پوشش رأسی\پاورقی{Vertex Coverage} را تعریف می‌کنیم.

\زیرقسمت{پوشش رأسی}
در این پایان‌نامه، از این مسئله به عنوان مسئله‌ی پایه برای اثبات ان‌پی-سخت بودن مسئله‌ی $k$-مرکز استفاده می‌شود. تعریف این مسئله مطابق زیر است:

\تعریف{گراف بدون جهت $G(V, E)$ داده شده است. هدف مسئله پیدا کردن مجموعه‌ی $S \subset V$ با کم‌ترین تعداد اعضا است به طوری که هر رأس $v \in V$ در یکی از شرایط زیر صدق کند:

\شروع{فقرات}

\فقره{$v \in S$}

\فقره{وجود دارد رأسی $u \in S$ به طوری $(v, u) \in E$}

\پایان{فقرات}

به عبارت ساده‌تر هر رأسی یا خودش یا یکی از همسایگانش داخل مجموعه‌ی $S$ قرار دارد.
}

نسخه‌ی تصمیم‌گیری این مسئله به این گونه تعریف می‌شود که آیا گراف داده‌شده دارای پوشش رأسی با اندازه‌ی $k$ است یا نه.

\قضیه{مسئله‌ی پوشش‌ رأسی، یک مسئله‌ی ان‌پی-سخت است.}

\شروع{اثبات}

برای مشاهده‌ی اثبات ان‌پی-سخت بودن مسئله‌ی پوشش رأسی, نیاز به زنجیره‌ای از مسائل که از مسئله‌ی صدق‌پذیری شروع می‌شود است, به طوری هر عضو از این زنجیره، به عضو بعدی در زمان چندجمله‌ای کاهش می‌یابد و در نهایت نتیجه می‌شود که مسئله‌ی صدق‌پذیری در زمان چندجمله‌ای به مسئله‌ی پوشش رأسی کاهش می‌یابد و در نتیجه چون مسئله‌ی صدق‌پذیری یک مسئله‌ی ان‌پی-سخت است، بنابراین مسئله‌ی پوشش رأسی نیز ان‌پی-سخت خواهد بود. برای مطالعه‌ی روند اثبات به مرجع \مرجع{sipser2012introduction} مراجعه کنید. 

\پایان{اثبات}

\قسمت{الگوریتم‌های تقریبی}

تا این‌جا با رده‌بندی مسائل به دو دسته‌ی پی و ان‌پی آشنا شدیم. نه تنها مسائل ان‌پی، بلکه بعضی از مسائل پی نیز دارای الگوریتم کارامدی نیستند. در عمل، یک الگوریتم چندجمله‌ای با مرتبه‌ی بیش از $3$، یک الگوریتم ناکارآمد محسوب می‌شود. به طور مثال هنوز‌ الگوریتم کارامدی برای فهمیدن این‌که یک عدد اول است یا نه پیدا نشده است، با اینکه الگوریتم ارائه شده یک الگوریتم چندجمله‌ای است. عمده‌ی مسائل کاربردی مطرح در دنیای واقع، یا متعلق به دسته‌ی ان‌پی هستند و در نتیجه راه‌حل چندجمله‌ای ندارند، یا اگر راه‌حل چند جمله‌ای داشته باشند، مرتبه‌ی چندجمله‌ای بالاست و در نتیجه راه‌حل کارآمدی محسوب نمی‌گردد. یکی از رویکردهای رایج در برابر چنین مسائلی، صرف نظر کردن از دقت راه‌حل‌هاست. به طور مثال راه‌حل‌های مکاشفه‌ای\پاورقی{Heuristic} گوناگونی برای مسائل مختلف به خصوص مسائل ان‌پی بیان شده است. این راه‌حل‌ها بدون این‌که تضمین کنند راه‌حل خوبی ارائه می‌دهند یا حتی جوابشان به جواب بهینه نزدیک است، اما با معیار‌هایی سعی در بهینه عمل کردن دارند و تا حد ممکن سعی در ارائه‌ی جواب بهینه یا نزدیک بهینه دارند. اما در عمل، تنها برای دسته‌ای از کاربردها پاسخ قابل قبولی ارائه می‌دهند. 

مشکل عمده‌ی راه‌حل‌های مکاشفه‌ای، عدم امکان استفاده‌ از آن‌ها برای تمام کاربردها است. بنابراین در رویکرد دوم که اخیرا نیز مطرح شده است و عمر کمی دارد، سعی در ارائه‌ی الگوریتم‌های مکاشفه‌ای شده است که تضمین می‌کنند اختلاف زیادی با الگوریتمی که جواب بهینه می‌دهد، نداشته باشند. در واقع این الگوریتم‌ها همواره و در هر شرایطی، تقریبی از جواب بهینه را ارائه می‌دهند. به چنین الگوریتم‌هایی، \مهم{الگوریتم‌های تقریبی}\پاورقی{Approximation Algorithm} می‌گویند. علت اصلی این نام‌گذاری، تقریب زدن جواب الگوریتم بهینه است. ضریب تقریب یک الگوریتم تقریبی، به حداکثر نسبت جواب الگوریتم تقریبی به جواب بهینه گفته می‌شود.

الگوریتم‌های تقریبی تنها به علت محدودیت کارایی الگوریتم‌هایی که جواب بهینه می‌دهند، مورد استفاده قرار نمی‌گیرند. هر نوع محدودیتی ممکن است، استفاده از الگوریتم تقریبی را نسبت به الگوریتمی که جواب بهینه می‌دهد، مقرون به صرفه کند. به طور مثال از جمله عوامل دیگری که ممکن است باعث این انتخاب شود، کاهش میزان حافظه‌ی مصرفی باشد. برای طیف وسیعی از مسائل، کمبود حافظه، باعث می‌شود الگوریتم‌هایی با حافظه‌ی مصرفی کم‌تر طراحی شود که به دقت الگوریتم‌های بهینه عمل نمی‌کند اما می‌تواند با مصرف کم‌تر به تقریبی از جواب بهینه دست یابد. معمولا چنین الگوریتم‌هایی حافظه‌ی مصرفی از مرتبه‌ی زیرخطی\پاورقی{Sublinear} دارند و به همین دلیل برای داده‌های حجیم بسیار کاربرد دارند.

\شروع{لوح}[t]
\وسط‌چین
\شروع{جدول}{|c|c|}
\خط‌پر
مسئله & کران پایین تقریب‌پذیری
\\
\خط‌پر
\خط‌پر
پوشش رأسی &‪1.3606 \مرجع{dinur2005hardness} \\
$k$-مرکز & 2\مرجع{vazirani2013approximation} \\ 
$k$-مرکز در فضای اقلیدسی & ۱.۸۲۲\مرجع{bern1996approximation} \\
$1$-مرکز در حالت جویبار داده & $\frac{1 + \sqrt{2}}{2}$ \مرجع{agarwal2010streaming} \\
$k$-مرکز با نقاط پرت و نقاط اجباری & 3\مرجع{charikar2001algorithms}\\
\خط‌پر
\پایان{جدول}

\شرح{نمونه‌هایی از ضرایب تقریب برای مسائل بهینه‌سازی}
\برچسب{جدول:تقریب‌پذیری}
\پایان{لوح}

\زیرقسمت{میزان تقریب‌پذیری مسائل}

همان‌طور که تا این‌جا دیدیم، یکی ار راه‌کارهایی که برای کارآمد کردن راه‌حل ارائه شده برای یک مسئله وجود دارد، استفاده از الگوریتم‌های تقریبی برای حل آن مسئله است. یکی از عمده‌ترین دغدغه‌های مطرح در الگوریتم‌های تقریبی کاهش ضریب تقریب است. حتی در بعضی از موارد حتی امکان ارائه‌ی الگوریتم تقریبی با ضریبی ثابت نیز وجود ندارد. به طور مثال، همان‌طور که در فصل کارهای پیشین بیان خواهد شد، الگوریتم تقریبی با ضریب تقریب کم‌تر از $2$، برای مسئله‌ی $k$-مرکز وجود ندارد مگر اینکه $P = NP$ باشد. برای مسائل مختلف، معمولا می‌توان کران پایینی برای میزان تقریب‌پذیری آن‌ها ارائه داد. در واقع برای مسائل ان‌پی، علاوه بر این الگوریتم کارآمدی وجود ندارد، بعضا الگوریتم تقریبی برای حل آن با ضریبی تقریب کم و نزدیک به یک نیز وجود ندارد. در جدول \رجوع{جدول:تقریب‌پذیری} از میزان تقریبی مسائل مختلفی که در این پایان‌نامه مورد استفاده قرار می‌گیرد ببینید.

\قسمت{الگوریتم‌های جویبارداده}
در علوم کامپیوتر، الگوریتم جویبارداده به الگوریتم‌هایی گفته می‌شود که برای پردازش جویبارهای داده طراحی شده‌اند به طوری که ورودی آن‌، به صورت دنباله‌ای از داده‌‌ها داده می‌شود و تنها می‌توان تعدادی محدود بار، از روی دنباله گذر کرد (معمولا تنها یک بار ). الگوریتم‌های جویبار داده معمولا محدودیت شدیدی در حافظه دارند(نسبت به اندازه‌ی ورودی) و به علت تعداد زیاد داده‌ها، محدودیت زمانی پردازش برای هر داده نیز مطرح است.

چنین محدودیت‌هایی معمولا باعث می‌شود که الگوریتم جویبارداده  تنها بتواند یک جواب تقریبی از جواب بهینه را با استفاده از‌ اطلاعات مختصری که در حافظه نگه می‌دارد را ارائه دهد.

\زیرقسمت{مقدمه}

در سال‌های اخیر، پیشرفت‌های حوزه‌ی تکنولوژی، امکان جمع‌آوری داده‌ها را به صورت پوسته ممکن ساخته است. به طور مثال می‌توان از تراکنش‌های بانکی، استفاده از تلفن همراه یا مرورگر وب خود را در نظر بگیرید. در هر تعاملی که با این سیستم‌ها انجام می‌دهید، میزان زیادی داده تولید شده و ذخیره می‌گردد. در اکثر مواقع می‌توان این حجم عظیم داده را مورد پردازش قرار داد و اطلاعات بسیار مفیدی از آن، استخراج نمود. زمانی که حجم داده‌ بسیار زیاد باشد، معمولا چالش‌های محاسباتی و الگوریتمی برای الگوریتم‌ها به وجود می‌آورد. از جمله‌ی آن‌ها می‌توان به موارد زیر اشاره کرد:
\شروع{فقرات}
 
\فقره{با افزایش حجم داده، امکان پردازش داده‌ها به صورت کارامد با چندبار عبور کردن از جویبار داده وجود ندارد. یکی از مهم‌ترین موانع در طراحی الگوریتم‌های کارامد برای مدل جویبارداده این است که الگوریتم‌ها مجبور هستند هر داده را حداکثر یک بار مورد پردازش قرار دهند. بنابراین الگوریتم‌های مدل جویبار داده، معمولا تک‌گذره‌اند.}

\فقره{در اکثر الگوریتم‌های جویبار داده، از یک واحد برای پردازش داده‌ها به صورت محلی استفاده می‌شود. علت اصلی وجود چنین واحدی، نیاز این الگوریتم‌ها به تشخیص تغییرات در داده‌های ورودی است. این عملکرد الگوریتم‌های جویبار داده را می‌توان نوعی استفاده از اصل محل‌گرایی\پاورقی{Locality} محسوب نمود. اما مشکل عمده‌ی این نوع رویکرد اجتناب ناپذیر، در عمده‌ی موارد، عدم امکان راه‌حلی مناسب برای مسئله است. در ساخت الگوریتم‌های جویبار داده، باید دقت و تمرکز عمده‌ای را صرف تشخیص نحوه‌ی تغییر داده‌های ورودی نمود. }

\فقره{یکی از مهم‌ترین مشخصه‌های جویبار داده‌ها، ماهیت عدم متمرکز بودن داده‌ها است. از طرفی یک پردازنده به تنهایی دارای محدودیت بسیار زیادی از نظر قدرت پردازشی و حافظه است. بنابراین معمولا الگوریتم‌های جویبار داده، به گونه‌ای طراحی می‌شوند که قابل توزیع‌پذیری بوده و توانایی اجرا شدن به صورت چندروندی\پاورقی{Multi Thread} را دارا باشند.}

\پایان{فقرات} 

\زیرقسمت{گونه‌های مطرح}
در مدل جویبارداده، بعضی یا همه‌ی نقاط ورودی که باید پردازش گردند برای دسترسی تصادفی\پاورقی{Random access} از حافظه‌ی اصلی یا حافظه‌ی جانبی در دسترس نیستند، بلکه به مرور زمان، به صورت جویبار یا جویبارهایی از داده در اختیار الگوریتم قرار می‌گیرند \مرجع{aggarwal2007data}.

هر جویبار را می‌توان به عنوان دنباله‌ای مرتب از‌ نقاط(یا به‌روزرسانی‌ها\پاورقی{Update}) در نظر گرفت به طوری که به ترتیب دنباله قابل دسترسی هستند و هر کدام را تنها به تعدادی محدود بار(معمولا یک بار) می‌توان خواند \مرجع{aggarwal2007data}.

مسائل زیادی در این مدل مورد بررسی قرار گرفته‌اند که از جمله مهم‌ترین آن‌ها می‌توان به موارد زیر اشاره کرد:

\شروع{فقرات}

\فقره{محاسبه‌ی آماری مربوط به توزیع داده‌های یک جویبارداده‌ که به قدری بزرگ هستند قابل ذخیره شدن نیست.}

\فقره{مسائل مربوط به گراف‌ها، به طوری که ماتریس مجاورت گراف به ترتیب دلخواهی به صورت جویبارداده به الگوریتم داده می‌شود.}

\فقره{مسائل مربوط به دنباله‌ها و استخراج اطلاعات از دنباله‌ها که وابستگی شدیدی به ترتیب اعضای دنباله دارند، مانند پیدا کردن طولانی‌ترین زیردنباله با اعضای صعودی یا پیدا کردن تعداد نابه‌جایی‌های\پاورقی{Inversion} داخل دنباله. \مرجع{aggarwal2007data} }

\زیرقسمت{تحلیل الگوریتم‌های جویبار داده}

کارایی یک الگوریتم جویبار داده بر اساس سه معیار زیر اندازه‌گیری می‌شود:

\شروع{فقرات}

\فقره{تعداد مرتبه‌ای که الگوریتم از روی جویبار داده گذر می‌کند}

\فقره{میزان حافظه‌ی مصرفی}

\فقره{زمان مصرفی به ازای هر داده}

\پایان{فقرات}

الگوریتم‌های جویبار داده تشابه‌های زیادی با الگوریتم‌های برخط\پاورقی{Online} دارند. به طور مثال، هر دو نوع الگوریتم، نیاز دارند قبل ازینکه تمام ورودی فرا برسد، در مورد داده‌ی جویبار داده تصمیم بگیرند. اما تفاوت‌های عمده‌ای نیز در این الگوریتم‌ها وجود دارد. الگوریتم‌های جویبار داده، دارای حافظه‌ی محدودی هستند، اما می‌توانند تصمیم‌گیری راجع به یک داده را تا چند مرحله به عقب بیاندازند، در صورتی که الگوریتم‌های برخط، به محض ورود داده، باید در مورد آن تصمیم بگیرند.

\پایان{فقرات}

\زیرقسمت{مجموعه هسته}

یکی ار تکنیک‌های رایج در الگوریتم‌های جویبار داده، نگه‌داری نماینده‌ای با اندازه‌ی بسیار کوچک‌تر نسبت جویبار داده است. این مجموعه معمولا دغدغه‌ی محدودیت حافظه را در الگوریتم‌های جویبارداده برطرف می‌کند. به چنین مجموعه‌ای, مجموعه هسته می‌گوییم. حال به تعریف رسمی هسته می‌پردازیم:

\شروع{تعریف}

فرض کنید $\mu$ یک تابع اندازه‌گیری\پاورقی{Measure Function}(همانند تابع عرض مجموعه‌ای از نقاط) از $\IR^d$ به اعداد حقیقی نامنفی $\IR^d \cup \set{0}$ باشد. فرض کنید که این تابع، یک تابع یکنواخت است، یعنی به ازای هر دو مجموعه‌ی $P_1$ و $P_2$ که $P_1 \subset P_2$ است، آن‌گاه
$$\mu(P_1) \leq \mu(P_2)$$
فرض کنید $\epsilon > 0$ داده شده است، به زیرمجموعه‌ی $Q \subset P$ یک $\epsilon$-مجموعه‌ی هسته برای مجموعه $P$ است اگر رابطه‌ی زیر برقرار باشد:
$$(1 - \epsilon) \mu(P) \leq \mu (Q)$$

\پایان{تعریف}